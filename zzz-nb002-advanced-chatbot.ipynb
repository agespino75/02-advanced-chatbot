{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d733e1a-fff5-4739-b702-cc4af0a69d41",
   "metadata": {},
   "source": [
    "# How to build an advanced Chatbot with session memory using LangChain\n",
    "* Advanced Chatbot LLM App.\n",
    "    * Will be able to have a conversation.\n",
    "    * Will remember previous interactions: will have memory.\n",
    "    * Will be able to have different memories for different user sessions.\n",
    "    * Will be able to remember a limited number of messages: limited memory.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0399355-dece-4701-9bf4-4c204fe74929",
   "metadata": {},
   "source": [
    "## Concepts included\n",
    "* Chat Model vs. LLM Model:\n",
    "    *  Chat Model is based around messages.\n",
    "    *  LLM Model is based around raw text.\n",
    "* Chat History: allows Chat Model to remember previous interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48386f20-c929-48a9-8720-0953fcd67dd0",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65ee060-21f2-4e01-b283-1fd656dac1e9",
   "metadata": {},
   "source": [
    "#### After you download the code from the github repository in your computer\n",
    "In terminal:\n",
    "* cd project_name\n",
    "* pyenv local 3.11.4\n",
    "* poetry install\n",
    "* poetry shell\n",
    "\n",
    "#### To open the notebook with Jupyter Notebooks\n",
    "In terminal:\n",
    "* jupyter lab\n",
    "\n",
    "Go to the folder of notebooks and open the right notebook.\n",
    "\n",
    "#### To see the code in Virtual Studio Code or your editor of choice.\n",
    "* open Virtual Studio Code or your editor of choice.\n",
    "* open the project-folder\n",
    "* open the 002-advanced-chatbot.py file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f2adf5-45d7-4c4b-aa6b-3176daa86e0e",
   "metadata": {},
   "source": [
    "## Create your .env file\n",
    "* In the github repo we have included a file named .env.example\n",
    "* Rename that file to .env file and here is where you will add your confidential api keys. Remember to include:\n",
    "* OPENAI_API_KEY=your_openai_api_key\n",
    "* LANGCHAIN_TRACING_V2=true\n",
    "* LANGCHAIN_ENDPOINT=https://api.smith.langchain.com\n",
    "* LANGCHAIN_API_KEY=your_langchain_api_key\n",
    "* LANGCHAIN_PROJECT=your_project_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a63ff6-99ff-4629-b965-547d12a99ba6",
   "metadata": {},
   "source": [
    "We will call our LangSmith project **002-advanced-chatbot**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67075f4a-6c25-41db-b851-51df80ffd927",
   "metadata": {},
   "source": [
    "## Trick to avoid the nasty deprecation warnings from LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49577308-4ed9-4c4b-a59a-a825b33ea75d",
   "metadata": {},
   "source": [
    "In this exercise we will use the LangChain legacy chain LLMChain. It works well, but LangChain displays a nasty deprecation warning. To avoid it, we will enter the following code:"
   ]
  },
  {
   "cell_type": "code",
   "id": "157958ab-f806-4ced-9a9a-bd22cf61e946",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T15:04:46.679896Z",
     "start_time": "2025-06-18T15:04:46.668612Z"
    }
   },
   "source": [
    "import warnings\n",
    "from langchain._api import LangChainDeprecationWarning\n",
    "\n",
    "warnings.simplefilter(\"ignore\", category=LangChainDeprecationWarning)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "1b9bf0fd-0661-4350-8979-53266845c8dd",
   "metadata": {},
   "source": [
    "## Connect with the .env file located in the same directory of this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b08934-b7f0-4e8a-b5f7-9df3c8bdbc66",
   "metadata": {},
   "source": [
    "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac4cec3-cc60-49f1-a24e-793b3be7cc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "id": "992ec4a9-aa01-4e44-aeb9-b9a1f3aa9e54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T15:04:49.505323Z",
     "start_time": "2025-06-18T15:04:49.498291Z"
    }
   },
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "6c01d18b-f9f0-427b-a9dc-3d1885160578",
   "metadata": {},
   "source": [
    "#### Install LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff5ddc8-1f67-4efc-b26f-5a7bfb8fda5c",
   "metadata": {},
   "source": [
    "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed746499-d1b8-41e5-b131-270cf5fa229b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2af3ef-c2c7-445f-92bd-a29c68abce25",
   "metadata": {},
   "source": [
    "## Connect with an LLM and start a conversation with it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e646540d-6dae-468c-b5e0-5348106d034b",
   "metadata": {},
   "source": [
    "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fa7337f-3d60-4ede-bdf8-aa7a5cffec43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce3551e-95ca-41a1-8810-89c495bf93ab",
   "metadata": {},
   "source": [
    "* For this project, we will use OpenAI's gpt-3.5-turbo"
   ]
  },
  {
   "cell_type": "code",
   "id": "9afcbc7d-a816-41e3-925f-850883f5770d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T15:04:54.830892Z",
     "start_time": "2025-06-18T15:04:54.053247Z"
    }
   },
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chatbot = ChatOpenAI(model=\"gpt-4o-mini\")"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T15:05:13.472836Z",
     "start_time": "2025-06-18T15:05:13.467501Z"
    }
   },
   "cell_type": "code",
   "source": "print(chatbot.model_name)",
   "id": "648735e3af639620",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4o-mini\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "b0a1d409-7f2f-40a4-90c5-ad77dad3edce",
   "metadata": {},
   "source": [
    "* Human Message: the user input."
   ]
  },
  {
   "cell_type": "code",
   "id": "c5dc0613-fb6d-4c82-a614-9e7307714303",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T15:09:00.592379Z",
     "start_time": "2025-06-18T15:09:00.573821Z"
    }
   },
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "messagesToTheChatbot = [\n",
    "    HumanMessage(content=\"My favourite color is black.\"),\n",
    "]"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "479b36ec-341a-47bc-af32-30cfb939810d",
   "metadata": {},
   "source": [
    "#### Call the ChatModel (the LLM)"
   ]
  },
  {
   "cell_type": "code",
   "id": "db815e32-8e60-46b3-8cce-fbf40e378397",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T15:09:14.407716Z",
     "start_time": "2025-06-18T15:09:13.021553Z"
    }
   },
   "source": [
    "chatbot.invoke(messagesToTheChatbot)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"That's great! Black is often associated with elegance, sophistication, and even mystery. It can be a powerful color choice in fashion, design, and art. Do you have a favorite way to incorporate black into your life, like in clothing, decor, or something else?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 54, 'prompt_tokens': 13, 'total_tokens': 67, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-BjohVORCyBNrfwqSwHdxEoMXb6CkV', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--aa277b43-18b0-464f-ad90-137245c9f30e-0', usage_metadata={'input_tokens': 13, 'output_tokens': 54, 'total_tokens': 67, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "9913fc8c-254f-410d-aa8f-35eb0898855e",
   "metadata": {},
   "source": [
    "#### Track the operation in LangSmith\n",
    "* [Open LangSmith here](smith.langchain.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e62b67b-9798-4705-8b8a-dbfdf8c93ed8",
   "metadata": {},
   "source": [
    "## Check if the Chatbot remembers your favorite color."
   ]
  },
  {
   "cell_type": "code",
   "id": "c0ead4ee-bda3-4c52-9bdb-7bf234733055",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T15:09:26.765698Z",
     "start_time": "2025-06-18T15:09:25.612256Z"
    }
   },
   "source": [
    "chatbot.invoke([\n",
    "    HumanMessage(content=\"What is my favorite color?\")\n",
    "])"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I don't have access to personal information, so I can't know your favorite color. However, if you tell me what it is, I'd love to hear about it!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 13, 'total_tokens': 46, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_62a23a81ef', 'id': 'chatcmpl-BjohhW6goE9XHm8e3CfweVQXZtkQB', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--8487bd14-9e38-4144-8e13-01bff3057887-0', usage_metadata={'input_tokens': 13, 'output_tokens': 33, 'total_tokens': 46, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "faec947e-b9b7-43e3-ac67-60027e049f3c",
   "metadata": {},
   "source": [
    "* As you can see, our Chatbot cannot remember our previous interaction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df0143e-8bc8-45ad-ac6f-05aaf659c683",
   "metadata": {},
   "source": [
    "## Let's add memory to our Chatbot\n",
    "* We will use the ChatMessageHistory package.\n",
    "* We will save the Chatbot memory in a python dictionary called chatbotMemory.\n",
    "* We will define the get_session_history function to create a session_id for each conversation.\n",
    "* We will use the built-in runnable RunnableWithMesageHistory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2680fc-8b7a-429f-a570-3c3dc4681037",
   "metadata": {},
   "source": [
    "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23533a37-6060-4d32-9b0c-36a9ea57a634",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "id": "95c1d395-0656-46f4-a14e-70cd3e30e947",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T15:19:00.939271Z",
     "start_time": "2025-06-18T15:19:00.872374Z"
    }
   },
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "chatbotMemory = {}\n",
    "\n",
    "# input: session_id, output: chatbotMemory[session_id]\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in chatbotMemory:\n",
    "        chatbotMemory[session_id] = ChatMessageHistory()\n",
    "    return chatbotMemory[session_id]\n",
    "\n",
    "\n",
    "chatbot_with_message_history = RunnableWithMessageHistory(\n",
    "    chatbot, \n",
    "    get_session_history\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "441ef148-1c37-4006-bb02-780d994803bd",
   "metadata": {},
   "source": [
    "#### What is BaseChatMessageHistory and what it does?\n",
    "BaseChatMessageHistory is what is called an **abstract base class** in Python. [See more info about this here](https://api.python.langchain.com/en/latest/chat_history/langchain_core.chat_history.BaseChatMessageHistory.html). This means it serves as a template or a foundational **blueprint for other classes**. It outlines a set of methods and structures that any class inheriting from it must implement or adhere to, but it cannot be used to create objects directly.\n",
    "\n",
    "Here's a simpler breakdown of what it means for `BaseChatMessageHistory` to be an abstract base class:\n",
    "\n",
    "1. **Blueprint for Other Classes:** It provides a predefined structure that other classes can follow. Think of it like an outline or a checklist for building something; it specifies what needs to be included, but it isn’t the final product.\n",
    "\n",
    "2. **Cannot Create Instances:** You cannot create an instance of an abstract base class. Trying to create an object directly from `BaseChatMessageHistory` would result in an error because it's meant to be a guide, not something to use directly.\n",
    "\n",
    "3. **Requires Implementation:** Any class that inherits from this abstract base class needs to implement specific methods outlined in `BaseChatMessageHistory`, such as methods for adding messages, retrieving messages, and clearing messages. The class sets the rules, and the subclasses need to follow these rules by providing the actual operational details.\n",
    "\n",
    "4. **Purpose in Design:** Using an abstract base class helps ensure consistency and correctness in the implementation of classes that extend it. It's a way to enforce certain functionalities in any subclass, making sure that they all behave as expected without rewriting the same code multiple times.\n",
    "\n",
    "Overall, the concept of an abstract base class is about setting standards and rules, while leaving the specific details of execution to be defined by subclasses that inherit from it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985c9c5e",
   "metadata": {},
   "source": [
    "#### Let's explain the previous code in simple terms\n",
    "The previous code manages the chatbot's memory of conversations based on session identifiers. Here’s a breakdown of what the different components do:\n",
    "\n",
    "1. **chatbotMemory**:\n",
    "    - `chatbotMemory = {}`: This initializes an empty dictionary where session IDs and their respective chat histories will be stored.\n",
    "\n",
    "2. **get_session_history Function**:\n",
    "    - This function, `get_session_history`, takes a `session_id` as an argument and returns the chat history associated with that session.\n",
    "    - If a chat history for the given `session_id` does not exist in `chatbotMemory`, a new instance of `ChatMessageHistory` is created and assigned to that `session_id` in the dictionary.\n",
    "    - The function ensures that each session has its own unique chat history, stored and retrieved using the session ID.\n",
    "\n",
    "3. **chatbot_with_message_history**:\n",
    "    - `chatbot_with_message_history = RunnableWithMessageHistory(chatbot, get_session_history)`: This line creates an instance of `RunnableWithMessageHistory` using two arguments: `chatbot` and `get_session_history`.\n",
    "    - The `chatbot` is passed along with the `get_session_history` function. This setup integrates the chatbot with the functionality to handle session-specific chat histories, allowing the chatbot to maintain continuity and context in conversations across different sessions.\n",
    "    - **Learn more about RunnableWithMessageHistory** [here](https://python.langchain.com/v0.1/docs/expression_language/how_to/message_history/).\n",
    "\n",
    "Overall, the code organizes and manages a chatbot's memory, enabling it to handle different sessions with users effectively by remembering previous messages within each session."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98864e16-66bb-49fb-a72f-2ceb5523b361",
   "metadata": {},
   "source": [
    "#### RunnableWithMessageHistory\n",
    "**When invoking a new RunnableWithMessageHistory, we specify the corresponding chat history using a configurable parameter**. Let's say we want to create a chat memory for one user session, let's call it session1:"
   ]
  },
  {
   "cell_type": "code",
   "id": "4d51d451-ed97-4752-88df-de8072e45f71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T15:21:42.492002Z",
     "start_time": "2025-06-18T15:21:42.481537Z"
    }
   },
   "source": [
    "session1 = {\"configurable\": {\"session_id\": \"001\"}}"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "e6d3961a-b565-45b5-a45f-2332ab03cd87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T15:24:30.983330Z",
     "start_time": "2025-06-18T15:24:29.336168Z"
    }
   },
   "source": [
    "responseFromChatbot = chatbot_with_message_history.invoke(\n",
    "    [HumanMessage(content=\"My favorite color is black.\")],\n",
    "    config=session1,\n",
    ")\n",
    "\n",
    "responseFromChatbot.content"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"That's great! Black is often associated with elegance, sophistication, and versatility. It can convey a sense of mystery and depth as well. Do you have a favorite item or clothing that you love in black?\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "378a4aae-c392-439d-a7ea-4ae91a677075",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T15:24:40.661391Z",
     "start_time": "2025-06-18T15:24:39.946120Z"
    }
   },
   "source": [
    "responseFromChatbot = chatbot_with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's my favorite color?\")],\n",
    "    config=session1,\n",
    ")\n",
    "\n",
    "responseFromChatbot.content"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your favorite color is black!'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "78d37c98-3883-4210-a162-5302e109e743",
   "metadata": {},
   "source": [
    "## Let's now change the session_id and see what happens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b484c1-da0b-4e90-a304-afbbebe63b76",
   "metadata": {},
   "source": [
    "Now let's create a chat memory for another user session, let's call it session2:"
   ]
  },
  {
   "cell_type": "code",
   "id": "0f82b3e0-7897-4aa8-b554-1985a3af4a70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T15:24:47.129963Z",
     "start_time": "2025-06-18T15:24:47.127258Z"
    }
   },
   "source": [
    "session2 = {\"configurable\": {\"session_id\": \"002\"}}"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "id": "75248e78-2662-4faa-bd41-4aa2b7963d19",
   "metadata": {},
   "source": [
    "If the chatbot is using this new memory for session2, it will not be able to remember anything from the previous conversation in the session1:"
   ]
  },
  {
   "cell_type": "code",
   "id": "882d0fc2-4360-4205-8cc7-bc7275295eef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T15:25:03.636880Z",
     "start_time": "2025-06-18T15:25:02.342166Z"
    }
   },
   "source": [
    "responseFromChatbot = chatbot_with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's my favorite color?\")],\n",
    "    config=session2,\n",
    ")\n",
    "\n",
    "responseFromChatbot.content"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm not sure what your favorite color is! If you'd like to share it, I'd be happy to hear.\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "eb0ec598-2b9f-4da1-b169-b270f820df9e",
   "metadata": {},
   "source": [
    "## Let's go back to session1 and see if the memory is still there"
   ]
  },
  {
   "cell_type": "code",
   "id": "f36c102a-1f06-490f-88b7-cb6e6380d926",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T15:25:11.760570Z",
     "start_time": "2025-06-18T15:25:11.757743Z"
    }
   },
   "source": [
    "session1 = {\"configurable\": {\"session_id\": \"001\"}}"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "35f61f9a-b8d5-4149-97cd-c7b6c8683bc9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T15:25:28.223359Z",
     "start_time": "2025-06-18T15:25:27.617755Z"
    }
   },
   "source": [
    "responseFromChatbot = chatbot_with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's my favorite color?\")],\n",
    "    config=session1,\n",
    ")\n",
    "\n",
    "responseFromChatbot.content"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your favorite color is black!'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "id": "34cd5156-977b-42e9-89e9-7797f6895ebc",
   "metadata": {},
   "source": [
    "As we can see, the chatbot is now able to remember the session1 conversation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f037264c-71aa-47f2-9512-e78c12761eaa",
   "metadata": {},
   "source": [
    "## Our ChatBot has session memory now. Let's check if it remembers the conversation from session2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fac2a638-7968-4475-8cf8-9af8440f3acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "session2 = {\"configurable\": {\"session_id\": \"002\"}}"
   ]
  },
  {
   "cell_type": "code",
   "id": "d367cb8f-1109-45ca-8e7a-1b76a096ec86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T15:25:39.288421Z",
     "start_time": "2025-06-18T15:25:38.495374Z"
    }
   },
   "source": [
    "responseFromChatbot = chatbot_with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Mi name is Beto.\")],\n",
    "    config=session2,\n",
    ")\n",
    "\n",
    "responseFromChatbot.content"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nice to meet you, Beto! Do you want to share your favorite color with me?'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "39ac2ecd-9800-467e-a612-9e3264185875",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T15:25:45.521680Z",
     "start_time": "2025-06-18T15:25:44.692880Z"
    }
   },
   "source": [
    "responseFromChatbot = chatbot_with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my name?\")],\n",
    "    config=session2,\n",
    ")\n",
    "\n",
    "responseFromChatbot.content"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Beto. How can I assist you today?'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "c649bdcc-a393-406b-8121-4cd25ae11163",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T15:25:56.961765Z",
     "start_time": "2025-06-18T15:25:56.427680Z"
    }
   },
   "source": [
    "responseFromChatbot = chatbot_with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my favorite color?\")],\n",
    "    config=session1,\n",
    ")\n",
    "\n",
    "responseFromChatbot.content"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your favorite color is black.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T15:26:23.343241Z",
     "start_time": "2025-06-18T15:26:22.294913Z"
    }
   },
   "cell_type": "code",
   "source": [
    "responseFromChatbot = chatbot_with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my name?\")],\n",
    "    config=session1,\n",
    ")\n",
    "\n",
    "responseFromChatbot.content"
   ],
   "id": "fb6a7f745697e75d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I don’t know your name, but I’d be happy to learn it if you’d like to share!'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "id": "1cbce7cd-399d-42f3-be81-bff26506cfbc",
   "metadata": {},
   "source": [
    "## Our chatBot now remembers each of our conversations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39070b3d-5de9-4751-966e-98b17a4db745",
   "metadata": {},
   "source": [
    "## The importance to manage the Conversation History\n",
    "* The memory of a chatbot is included in the context window of the LLM so, if left unmanaged, can potentially overflow it.\n",
    "* **We are now going to learn how to limit the size of the memory of a chatbot**.\n",
    "* First, let's take a look at what is in the memory of our chatbot:"
   ]
  },
  {
   "cell_type": "code",
   "id": "09547883-82fc-480a-8f58-fd7fbc007fdf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T15:34:01.255375Z",
     "start_time": "2025-06-18T15:34:01.236162Z"
    }
   },
   "source": "print(chatbotMemory[\"002\"])",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: What's my favorite color?\n",
      "AI: I'm not sure what your favorite color is! If you'd like to share it, I'd be happy to hear.\n",
      "Human: Mi name is Beto.\n",
      "AI: Nice to meet you, Beto! Do you want to share your favorite color with me?\n",
      "Human: What is my name?\n",
      "AI: Your name is Beto. How can I assist you today?\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "id": "056a7229-ea29-468b-93e1-b2b52951b47c",
   "metadata": {},
   "source": [
    "* Now, **let's define a function to limit the number of messages stored in memory and add it to our chain with .assign**."
   ]
  },
  {
   "cell_type": "code",
   "id": "cd33a1bb-d3c4-4011-99c7-105e3d7051e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T15:38:37.419684Z",
     "start_time": "2025-06-18T15:38:37.414196Z"
    }
   },
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "\n",
    "def limited_memory_of_messages(messages, number_of_messages_to_keep=10):\n",
    "    return messages[-number_of_messages_to_keep:]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Answer all questions to the best of your ability.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "limitedMemoryChain = (\n",
    "    RunnablePassthrough.assign(messages=lambda x: limited_memory_of_messages(x[\"messages\"]))\n",
    "    | prompt \n",
    "    | chatbot\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 38
  },
  {
   "cell_type": "markdown",
   "id": "0ff26a10-27aa-48ef-a3f0-867d3f819c79",
   "metadata": {},
   "source": [
    "* The limited_memory_of_messages function allows you to trim the list of stored messages, keeping only a specified number of the latest ones. For example, if you have a long list of messages and you only want to keep the last two, this function will do that for you.\n",
    "* The lambda function works in conjunction with the `limited_memory_of_messages` function. Here’s a simple breakdown:\n",
    "\n",
    "    1. **Lambda Function**: The `lambda` keyword is used to create a small anonymous function in Python. The `lambda` function defined here takes one argument, `x`.\n",
    "\n",
    "    2. **Function Argument**: The argument `x` is expected to be a dictionary that contains a key named `\"messages\"`. The value associated with this key is a list of messages.\n",
    "\n",
    "    3. **Function Body**: The body of the `lambda` function calls the `limited_memory_of_messages` function. It passes the list of messages found in `x[\"messages\"]` to this function.\n",
    "\n",
    "    4. **Default Behavior of limited_memory_of_messages**: Since the `lambda` function does not specify the `number_of_messages_to_keep` parameter when it calls `limited_memory_of_messages`, the latter will default to keeping the last 2 messages from the list (as defined by the earlier function).\n",
    "\n",
    "In essence, the `lambda` function is a shorthand way to apply the `limited_memory_of_messages` function to the message list contained within a dictionary. It automatically trims the list to the last two messages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac98d2fd-4e32-4c71-a0c0-99701534f551",
   "metadata": {},
   "source": [
    "**Let's now create our new chatbot with limited message history**:"
   ]
  },
  {
   "cell_type": "code",
   "id": "e45d4cd1-2165-451d-939f-66f9cc898c65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T15:38:44.629768Z",
     "start_time": "2025-06-18T15:38:44.616703Z"
    }
   },
   "source": [
    "chatbot_with_limited_message_history = RunnableWithMessageHistory(\n",
    "    limitedMemoryChain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\",\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 39
  },
  {
   "cell_type": "markdown",
   "id": "f8b39981-02c7-4d10-a4a8-2efbe9bb3c89",
   "metadata": {},
   "source": [
    "## Let's add 2 more messages to the session1 conversation:"
   ]
  },
  {
   "cell_type": "code",
   "id": "76687e6a-2bbf-450f-8310-7011646fea3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T15:35:48.189667Z",
     "start_time": "2025-06-18T15:35:47.304050Z"
    }
   },
   "source": [
    "responseFromChatbot = chatbot_with_message_history.invoke(\n",
    "    [HumanMessage(content=\"My favorite vehicles are Ferraris.\")],\n",
    "    config=session1,\n",
    ")\n",
    "\n",
    "responseFromChatbot.content"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ferraris are fantastic! They’re known for their stunning design, incredible performance, and rich racing heritage. Do you have a favorite Ferrari model?'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "id": "4c8a9b0c-7ae5-4f3b-b93b-06462c6d3199",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T15:35:55.667022Z",
     "start_time": "2025-06-18T15:35:54.004260Z"
    }
   },
   "source": [
    "responseFromChatbot = chatbot_with_message_history.invoke(\n",
    "    [HumanMessage(content=\"My favorite city is Vancouver.\")],\n",
    "    config=session1,\n",
    ")\n",
    "\n",
    "responseFromChatbot.content"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Vancouver is a beautiful city! It's known for its stunning natural scenery, diverse culture, and vibrant arts scene. Do you have a favorite spot or activity in Vancouver?\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T15:43:08.496383Z",
     "start_time": "2025-06-18T15:43:08.489393Z"
    }
   },
   "cell_type": "code",
   "source": "print(chatbot_with_limited_message_history.get_session_history(session_id=\"001\").messages)",
   "id": "66e284dbca8766a1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='My favorite color is black.', additional_kwargs={}, response_metadata={}), AIMessage(content=\"That's great! Black is often associated with elegance, sophistication, and versatility. It can convey a sense of mystery and depth as well. Do you have a favorite item or clothing that you love in black?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 13, 'total_tokens': 54, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-BjowIeIhU1jH67c9bCZnAxHyBbHkK', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--16379b4c-2400-4a72-b56d-ab04e5d303e6-0', usage_metadata={'input_tokens': 13, 'output_tokens': 41, 'total_tokens': 54, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), HumanMessage(content=\"What's my favorite color?\", additional_kwargs={}, response_metadata={}), AIMessage(content='Your favorite color is black!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 67, 'total_tokens': 73, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-BjowST7VBC3iE6MpSsPBLeiXHwKb0', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--00bd917e-bf34-47e5-9871-538a772aef7c-0', usage_metadata={'input_tokens': 67, 'output_tokens': 6, 'total_tokens': 73, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), HumanMessage(content=\"What's my favorite color?\", additional_kwargs={}, response_metadata={}), AIMessage(content='Your favorite color is black!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 86, 'total_tokens': 92, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-BjoxD14q4uxBIfBi4HXjtNWetCg0N', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--7ad029d1-9658-47ff-ad40-c9fc85d9c813-0', usage_metadata={'input_tokens': 86, 'output_tokens': 6, 'total_tokens': 92, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), HumanMessage(content='What is my favorite color?', additional_kwargs={}, response_metadata={}), AIMessage(content='Your favorite color is black.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 106, 'total_tokens': 112, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-BjoxggZD4bOX2IBDhDcn4dNgFi5VY', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--9b7a00d3-902c-49ac-899b-2589c992d9d0-0', usage_metadata={'input_tokens': 106, 'output_tokens': 6, 'total_tokens': 112, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), HumanMessage(content='What is my name?', additional_kwargs={}, response_metadata={}), AIMessage(content='I don’t know your name, but I’d be happy to learn it if you’d like to share!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 125, 'total_tokens': 147, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_62a23a81ef', 'id': 'chatcmpl-Bjoy6eo4Bnqc7AiUqq9HWDMfhVKzN', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--85e8bd21-8557-48f0-8191-8c9433b95a3d-0', usage_metadata={'input_tokens': 125, 'output_tokens': 22, 'total_tokens': 147, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), HumanMessage(content='My favorite vehicles are Ferraris.', additional_kwargs={}, response_metadata={}), AIMessage(content='Ferraris are fantastic! They’re known for their stunning design, incredible performance, and rich racing heritage. Do you have a favorite Ferrari model?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 162, 'total_tokens': 191, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_62a23a81ef', 'id': 'chatcmpl-Bjp7DTWvx37QdbmmfTJJytVmvj0rY', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--9aefc1eb-08f3-43bb-a005-0be7fee01491-0', usage_metadata={'input_tokens': 162, 'output_tokens': 29, 'total_tokens': 191, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), HumanMessage(content='My favorite city is Vancouver.', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Vancouver is a beautiful city! It's known for its stunning natural scenery, diverse culture, and vibrant arts scene. Do you have a favorite spot or activity in Vancouver?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 205, 'total_tokens': 239, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_62a23a81ef', 'id': 'chatcmpl-Bjp7Kfn4YEyax5ZXjULusO3QBK0OO', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--21ea484b-7c94-44ad-8904-be59a88bc756-0', usage_metadata={'input_tokens': 205, 'output_tokens': 34, 'total_tokens': 239, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), HumanMessage(content='what is my favorite color?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"I'm not able to know your personal preferences, including your favorite color, unless you tell me. If you'd like to share it, I'd be happy to discuss it!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 71, 'total_tokens': 104, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-Bjp8ZYqHa7kYrQjOZlpNMvaYowmIL', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--362dbc8a-bf44-44e8-8d02-db57c54c84d3-0', usage_metadata={'input_tokens': 71, 'output_tokens': 33, 'total_tokens': 104, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), HumanMessage(content='what is my favorite color?', additional_kwargs={}, response_metadata={}), AIMessage(content='I still don’t know your favorite color. If you tell me what it is, I’d love to chat about it!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 80, 'total_tokens': 105, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-Bjp8wFK264zL5t1nD7jnKzssKX5tw', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--5e7234a1-d5b2-485a-b38e-090b6a88bae6-0', usage_metadata={'input_tokens': 80, 'output_tokens': 25, 'total_tokens': 105, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), HumanMessage(content='what is my favorite color?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"I can't determine your favorite color without you telling me. If you share it, I’d be glad to talk about it!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 237, 'total_tokens': 262, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-BjpAE6ywBIvoZGArGS2xhhVZkfJ6M', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--3cc2d170-0a96-4664-b3bb-2dc580ddbd95-0', usage_metadata={'input_tokens': 237, 'output_tokens': 25, 'total_tokens': 262, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), HumanMessage(content='what is my favorite color?', additional_kwargs={}, response_metadata={}), AIMessage(content='Your favorite color is black!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 378, 'total_tokens': 384, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_62a23a81ef', 'id': 'chatcmpl-BjpAVJ7EFWuV2GG2gASwoNezDphnK', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--fa4706f1-1d6d-4e30-8755-d2985e4d1c2e-0', usage_metadata={'input_tokens': 378, 'output_tokens': 6, 'total_tokens': 384, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "cell_type": "markdown",
   "id": "23c688e6-3e9f-4c11-a4f7-38eb8dd35666",
   "metadata": {},
   "source": [
    "## The chatbot memory has now 4 messages. Let's check the Chatbot with limited memory. \n",
    "* Remember, this chatbot only remembers the last 2 messages, so if we ask her about the first message she should not remember it."
   ]
  },
  {
   "cell_type": "code",
   "id": "16875068-39fd-419e-84b0-f3363f30a3e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T15:38:55.753345Z",
     "start_time": "2025-06-18T15:38:54.106767Z"
    }
   },
   "source": [
    "responseFromChatbot = chatbot_with_limited_message_history.invoke(\n",
    "    {\n",
    "        \"messages\": [HumanMessage(content=\"what is my favorite color?\")],\n",
    "    },\n",
    "    config=session1,\n",
    ")\n",
    "\n",
    "responseFromChatbot.content"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I can't determine your favorite color without you telling me. If you share it, I’d be glad to talk about it!\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "cell_type": "markdown",
   "id": "b9989ae1-d75b-4b8f-9235-b4eb110e102d",
   "metadata": {},
   "source": [
    "* The chatbot with limited memory has behaved as we expected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d324091a-dc49-42af-b638-324dc646cdae",
   "metadata": {},
   "source": [
    "## Finally, let's compare the previous response with the one provided by the Chatbot with unlimited memory"
   ]
  },
  {
   "cell_type": "code",
   "id": "251e1915-dabf-4591-82cc-a0fa8b465ec8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T15:39:12.255599Z",
     "start_time": "2025-06-18T15:39:11.054562Z"
    }
   },
   "source": [
    "responseFromChatbot = chatbot_with_message_history.invoke(\n",
    "    [HumanMessage(content=\"what is my favorite color?\")],\n",
    "    config=session1,\n",
    ")\n",
    "\n",
    "responseFromChatbot.content"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your favorite color is black!'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 41
  },
  {
   "cell_type": "markdown",
   "id": "b83e34b2-3c42-4ef7-9deb-18c2ec374adc",
   "metadata": {},
   "source": [
    "* As you can see, this chatbot remembers our first message."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f483274a-ad1f-4079-b053-ebdcde113ec0",
   "metadata": {},
   "source": [
    "## How to execute the code from Visual Studio Code\n",
    "* In Visual Studio Code, see the file 004-invoke-stream-batch.py\n",
    "* In terminal, make sure you are in the directory of the file and run:\n",
    "    * python 002-advanced-chatbot.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2ffb53-77c1-4e62-a47c-cf50af2a3634",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
